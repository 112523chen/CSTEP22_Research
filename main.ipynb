{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes directory to the datasets folder\n",
    "os.chdir(\"./datasets\")\n",
    "# stores directory to datasets folder to be used later to get the csv files\n",
    "root = os.getcwd()\n",
    "# stores files names in current directory (datasets) in a list to be used later get a dataFrame \n",
    "files = os.listdir()\n",
    "# removes hidden file \n",
    "files.remove(\".DS_Store\")\n",
    "# assign a dictionary to referenced in the future to store dataFrames\n",
    "datasets = dict()\n",
    "\n",
    "\n",
    "for item in files:\n",
    "\n",
    "    # converts csv files to dataFrames\n",
    "    path = str(f'{root}/{item}')\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # gets specific file \n",
    "    br = item.split(\"_\")\n",
    "    targets = br[1:]\n",
    "\n",
    "    # converts file name from snake case to camel case\n",
    "    for i in range(len(targets)):\n",
    "        if i > 0:\n",
    "            text = targets[i]\n",
    "            text = text.capitalize()\n",
    "            targets[i] = text\n",
    "    target = \"\".join(targets)\n",
    "    \n",
    "    # removes file type from the end of string\n",
    "    target = target[:-4]\n",
    "\n",
    "    #stores dataFrames with camel case file name as key\n",
    "    datasets[target] = df\n",
    "\n",
    "    # print(targets,target)\n",
    "\n",
    "# ! there will less datasets when compared to files in dataset folder since the is one instance of datasets spanning multiple questions\n",
    "# * { files: 30 , datasets: 25}\n",
    "\n",
    "# changes directory to back to parent directory\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_df = pd.read_csv('data_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    def __init__(self,id,title,prompt,question_type,python_difficulty,sql_difficulty,fileNames,company_name):\n",
    "        self.id = id\n",
    "        self.title = title\n",
    "        self.prompt = prompt\n",
    "        self.question_type = question_type\n",
    "        self.python_difficulty = python_difficulty\n",
    "        self.sql_difficulty = sql_difficulty\n",
    "        self.fileNames = fileNames\n",
    "        self.company_name = company_name\n",
    "    \n",
    "    def addFile(self,fileName):\n",
    "        return self.fileNames.append(fileName)\n",
    "\n",
    "# stores nested dictionary \n",
    "datasets_by_company = dict()\n",
    "\n",
    "# sorts dataframe by companies\n",
    "logic_by_company = logic_df.groupby(\"company_name\")\n",
    "\n",
    "#creates a list of unique company names\n",
    "companies = list(logic_df[\"company_name\"].unique())\n",
    "\n",
    "#creates a list of unique question IDs\n",
    "question_IDs = list(logic_df[\"question_id\"].unique())\n",
    "\n",
    "#creates a dictionary within another dictionary for referencing questions\n",
    "for company in companies:\n",
    "    if company not in datasets_by_company.keys():\n",
    "        datasets_by_company[company] = dict()\n",
    "\n",
    "#creates object for each question and inputs them into dictionary\n",
    "for question_id in question_IDs:\n",
    "    question_id_df = logic_df[logic_df['question_id'] == question_id]\n",
    "    title = question_id_df['title'].unique()[0]\n",
    "    company_name = question_id_df['company_name'].unique()[0]\n",
    "    prompt = question_id_df['prompt'].unique()[0]\n",
    "    question_type = question_id_df['question_type'].unique()[0]\n",
    "    python_difficulty =  question_id_df['python_difficulty'].unique()[0]\n",
    "    sql_difficulty =  question_id_df['mySQL_difficulty'].unique()[0]\n",
    "    filesNames = list(question_id_df['file'].unique())\n",
    "\n",
    "    f = title.split()\n",
    "    f = map(str.capitalize,f)\n",
    "    f = \"\".join(f)\n",
    "    \n",
    "    question = Question(question_id,title,prompt,question_type,python_difficulty,sql_difficulty,filesNames,company_name)\n",
    "\n",
    "    datasets_by_company[company_name][f] = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a DataFrame of dictionary\n",
    "test = dict()\n",
    "for k in datasets_by_company.keys():\n",
    "    for k2 in datasets_by_company[k].keys():\n",
    "        x = datasets_by_company[k][k2]\n",
    "        y = k2\n",
    "        test[k2] = vars(x)\n",
    "\n",
    "data = pd.DataFrame(test).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.sort()\n",
    "\n",
    "company_answer = input(f\"Enter company name from following \\n {companies}\")\n",
    "\n",
    "question_from_company = datasets_by_company[company_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Order Per Status Per Service\n"
     ]
    }
   ],
   "source": [
    "question_from_company = list(question_from_company.keys())\n",
    "\n",
    "question_title = input(f\"Enter question title from follow \\n {question_from_company}\")\n",
    "\n",
    "question = datasets_by_company[company_answer][question_title]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Total Order Per Status Per Service\n",
      "Prompt: Uber is interested in identifying gaps in their business. Calculate the count of orders for each status of each service. Your output should include the service name, status of the order, and the number of orders.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Title: {question.title}\")\n",
    "print(f\"Prompt: {question.prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DataFrame: ['totalOrderPerStatusPerService_uber_orders.csv']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting DataFrame: {question.fileNames}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
